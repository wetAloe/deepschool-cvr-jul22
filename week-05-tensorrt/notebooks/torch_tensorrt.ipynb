{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db2d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import gc\n",
    "\n",
    "from os import path\n",
    "import sys\n",
    "sys.path.append(path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103991fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnx\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import tensorrt as trt\n",
    "import matplotlib.pyplot as plt\n",
    "from timm import create_model\n",
    "import torch_tensorrt\n",
    "\n",
    "from src.transforms import torch_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad9148f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c664d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469fc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем и готовим торчовую модель\n",
    "torch_model = create_model('gernet_l', pretrained=True)\n",
    "_ = torch_model.to(DEVICE)\n",
    "_ = torch_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40f41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем картиночку\n",
    "image = cv2.imread('../data/dog.jpg')[..., ::-1]\n",
    "print(image.shape)\n",
    "Image.fromarray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fd5dd",
   "metadata": {},
   "source": [
    "## Батчевание\n",
    "\n",
    "Есть 2 режима:\n",
    " - явный (explicit) - указываем размер батча\n",
    " - неявный (implicit) - не указываем размер батча\n",
    " \n",
    "Но неявный \"устарел\" + не помню, чтобы в python действительно работал implicit размер батча. Поэтому всегда явный размер батча(\n",
    "\n",
    "А если хочу разные размеры батча?! Есть решение, дальше увидим."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2c75b0",
   "metadata": {},
   "source": [
    "## Статический размер батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf8c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc940582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим тензора для прогона\n",
    "torch_input_tensor = torch_preprocessing(image).to(DEVICE)\n",
    "torch_input_tensor = torch.cat([torch_input_tensor] * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ab35f",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe0e0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# прогон через торчовую модель\n",
    "with torch.no_grad():\n",
    "    torch_output_tensor = torch_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1870c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    torch_output_tensor = torch_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a84721",
   "metadata": {},
   "source": [
    "### TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим TensorRT модель с fp32\n",
    "trt_model = torch_tensorrt.compile(\n",
    "    torch_model,\n",
    "    inputs = [torch_tensorrt.Input((BATCH_SIZE, 3, 224, 224))],\n",
    "    enabled_precisions = torch.float32,\n",
    "    workspace_size = 1 << 30, # 1 гибибайт\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffccd797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогон через тенсоррт модель с fp32\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor = trt_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996f7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor = trt_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70785dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим TensorRT модель с fp16\n",
    "trt_model_fp16 = torch_tensorrt.compile(\n",
    "    torch_model,\n",
    "    inputs = [torch_tensorrt.Input((BATCH_SIZE, 3, 224, 224))],\n",
    "    enabled_precisions = torch.float16,\n",
    "    workspace_size = 1 << 30, # 1 гибибайт\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогон через тенсоррт модель с fp16\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor_fp16 = trt_model_fp16(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dc3139",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor_fp16 = trt_model_fp16(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c00ed",
   "metadata": {},
   "source": [
    "### Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85922bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Сравнение логитов\n",
    "print(f'fp32: {list(np.abs(trt_output_tensor - torch_output_tensor).max(1))[0]}')\n",
    "print(f'fp16: {list(np.abs(trt_output_tensor_fp16 - torch_output_tensor).max(1))[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acdb4e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Сравнение после активации\n",
    "print(f'fp32: {list(np.abs(softmax(trt_output_tensor) - softmax(torch_output_tensor)).max(1))[0]}')\n",
    "print(f'fp16: {list(np.abs(softmax(trt_output_tensor_fp16) - softmax(torch_output_tensor)).max(1))[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71743b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Финальный предикт\n",
    "print(f'torch: {list(softmax(torch_output_tensor).argmax(1))[0]}')\n",
    "print(f'fp32: {list(softmax(trt_output_tensor).argmax(1))[0]}')\n",
    "print(f'fp16: {list(softmax(trt_output_tensor_fp16).argmax(1))[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe381394",
   "metadata": {},
   "source": [
    "## Динамический размер батча"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb2a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26876b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим тензора для прогона\n",
    "torch_input_tensor = torch_preprocessing(image).to(DEVICE)\n",
    "torch_input_tensor = torch.cat([torch_input_tensor] * BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98fcedc",
   "metadata": {},
   "source": [
    "### Torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60e0ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# прогон через торчовую модель\n",
    "with torch.no_grad():\n",
    "    torch_output_tensor = torch_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da31caea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    torch_output_tensor = torch_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6d2bc5",
   "metadata": {},
   "source": [
    "### TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b994b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим TensorRT модель с fp32\n",
    "trt_model = torch_tensorrt.compile(\n",
    "    torch_model,\n",
    "    inputs = [\n",
    "        torch_tensorrt.Input(\n",
    "            min_shape=(1, 3, 224, 224),\n",
    "            opt_shape=(3, 3, 224, 224),\n",
    "            max_shape=(5, 3, 224, 224),\n",
    "    )],\n",
    "    enabled_precisions = torch.float32,\n",
    "    workspace_size = 1 << 30, # 1 гибибайт\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a8968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогон через тенсоррт модель с fp32\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor = trt_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeb76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor = trt_model(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f03b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# готовим TensorRT модель с fp16\n",
    "trt_model_fp16 = torch_tensorrt.compile(\n",
    "    torch_model,\n",
    "    inputs = [\n",
    "        torch_tensorrt.Input(\n",
    "            min_shape=(1, 3, 224, 224),\n",
    "            opt_shape=(3, 3, 224, 224),\n",
    "            max_shape=(5, 3, 224, 224),\n",
    "    )],\n",
    "    enabled_precisions = torch.float16,\n",
    "    workspace_size = 1 << 30, # 1 гибибайт\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfa15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# прогон через тенсоррт модель с fp16\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor_fp16 = trt_model_fp16(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e1664",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    trt_output_tensor_fp16 = trt_model_fp16(torch_input_tensor).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f701b",
   "metadata": {},
   "source": [
    "### Сравнение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49dead8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Сравнение логитов\n",
    "print(f'fp32: {list(np.abs(trt_output_tensor - torch_output_tensor).max(1))}')\n",
    "print(f'fp16: {list(np.abs(trt_output_tensor_fp16 - torch_output_tensor).max(1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f0204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Сравнение после активации\n",
    "print(f'fp32: {list(np.abs(softmax(trt_output_tensor) - softmax(torch_output_tensor)).max(1))}')\n",
    "print(f'fp16: {list(np.abs(softmax(trt_output_tensor_fp16) - softmax(torch_output_tensor)).max(1))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee856518",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Финальный предикт\n",
    "print(f'torch: {list(softmax(torch_output_tensor).argmax(1))}')\n",
    "print(f'fp32: {list(softmax(trt_output_tensor).argmax(1))}')\n",
    "print(f'fp16: {list(softmax(trt_output_tensor_fp16).argmax(1))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363be02f",
   "metadata": {},
   "source": [
    "## Сохранение и загрузка чекпоинта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d3c975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем на диск\n",
    "torch.jit.save(trt_model, \"../models/trt_torchscript_module.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5251c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем с диска\n",
    "new_trt_model = torch.jit.load('../models/trt_torchscript_module.ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f522e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch_output_tensor = new_trt_model(torch_input_tensor).cpu().detach().numpy()[0]\n",
    "print(softmax(torch_output_tensor).argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "with torch.no_grad():\n",
    "    torch_output_tensor = new_trt_model(torch_input_tensor).cpu().detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9fa46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
