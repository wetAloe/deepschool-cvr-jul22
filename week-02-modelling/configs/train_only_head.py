from functools import partial
import os

import albumentations as albu
import torch
from src.base_config import Config
from src.utils import preprocess_imagenet
from src.callbacks import FreezeModelParts
from src.scheduler import CosineAnnealingWarmUpRestarts
from torch.nn import BCEWithLogitsLoss

SEED = 42
IMG_SIZE = 224
BATCH_SIZE = 256
N_EPOCHS = 100
NUM_ITERATION_ON_EPOCH = 100
ROOT_PATH = os.path.join(os.environ.get("ROOT_PATH"))

augmentations = albu.Compose(
    [
        albu.HorizontalFlip(),
        albu.VerticalFlip(),
        albu.HueSaturationValue(
            hue_shift_limit=20,
            sat_shift_limit=30,
            val_shift_limit=20,
            p=0.5,
        ),
        albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
        albu.ShiftScaleRotate(),
        albu.GaussianBlur(),
    ]
)

callbacks = [
    FreezeModelParts(parts=['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']),  # Замораживаем претрен веса
]

config = Config(
    num_workers=4,
    seed=SEED,
    loss=BCEWithLogitsLoss(),
    optimizer=torch.optim.Adam,
    optimizer_kwargs={
        "lr": 1e-5,  # минимальное значение lr
        "weight_decay": 5e-4,
    },
    scheduler=CosineAnnealingWarmUpRestarts,
    scheduler_kwargs={
        'T_0': 5 * NUM_ITERATION_ON_EPOCH,  # будет 5 цикла
        'T_mult': 1,
        'eta_max': 1e-3,  # максимальный lr
        'T_up': 100,  # итераций warm up
        'gamma': 0.7,  # затухание амплитуды
    },
    img_size=IMG_SIZE,
    augmentations=augmentations,
    callbacks=callbacks,
    preprocessing=partial(preprocess_imagenet, img_size=IMG_SIZE),
    batch_size=BATCH_SIZE,
    num_iteration_on_epoch=NUM_ITERATION_ON_EPOCH,  # увеличиваем количество итераций на эпоху
    n_epochs=N_EPOCHS,
    model_kwargs={"model_name": "resnet18", "pretrained": True},
    log_metrics=["auc", "f1"],
    binary_thresh=0.1,
    valid_metric="auc",
    minimize_metric=False,
    images_dir=os.path.join(ROOT_PATH, "Images"),
    train_dataset_path=os.path.join(ROOT_PATH, "train_df.csv"),
    valid_dataset_path=os.path.join(ROOT_PATH, "valid_df.csv"),
    test_dataset_path=os.path.join(ROOT_PATH, "test_df.csv"),
    project_name="[Classification]MovieGenre",
    experiment_name=f'{os.path.basename(__file__).split(".")[0]}',
)
